{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb77c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79898c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./m_a_tkg/update_task/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331213e6",
   "metadata": {},
   "source": [
    "### Initial TKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1fe47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_list = pd.read_csv(data_path + 'entities_list_wiki_with_wikidata_0109.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40cbe594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "entities_list['qa_data'] = entities_list['qa_data'].apply(lambda x: ast.literal_eval(x))\n",
    "entities_list['eda_data'] = entities_list['eda_data'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ad50eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "wikidata_with_tuples = entities_list[entities_list['len_qa_data'] != 0]\n",
    "wikidata_with_tuples['qa_data'] = wikidata_with_tuples['qa_data'].apply(lambda x: list(dict.fromkeys(x)))\n",
    "wikidata_with_tuples['eda_data'] = wikidata_with_tuples['eda_data'].apply(lambda x: list(dict.fromkeys(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adcfc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_zero = list(zip(wikidata_with_tuples['lowered_entity_names'], wikidata_with_tuples['qa_data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf54712",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkg_dict = dict(ground_zero)\n",
    "all_tuples = []\n",
    "for key, item in tkg_dict.items():\n",
    "    all_tuples.append(item)\n",
    "flat_list = [item for sublist in all_tuples for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f6be91a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_tkg = pd.DataFrame(flat_list, columns=['head_entity', 'relation', 'tail_entity', 'start_date'])\n",
    "initial_tkg['end_date'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7c3d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_entity</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail_entity</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple_inc.</td>\n",
       "      <td>owner of (P1830)</td>\n",
       "      <td>Imagination Technologies (Q1119662)</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple_inc.</td>\n",
       "      <td>owner of (P1830)</td>\n",
       "      <td>Apple corporate shuttle (Q110553619)</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple_inc.</td>\n",
       "      <td>subsidiary (P355)</td>\n",
       "      <td>FileMaker, Inc. (Q1982831)</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple_inc.</td>\n",
       "      <td>subsidiary (P355)</td>\n",
       "      <td>Anobit (Q2893391)</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple_inc.</td>\n",
       "      <td>subsidiary (P355)</td>\n",
       "      <td>Beats Electronics (Q1961036)</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8349</th>\n",
       "      <td>sm_entertainment</td>\n",
       "      <td>subsidiary (P355)</td>\n",
       "      <td>SM Classics (Q105753127)</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>sm_entertainment</td>\n",
       "      <td>subsidiary (P355)</td>\n",
       "      <td>Label V (Q107463954)</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>sm_entertainment</td>\n",
       "      <td>subsidiary (P355)</td>\n",
       "      <td>Baljunso (Q18159635)</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8352</th>\n",
       "      <td>sm_entertainment</td>\n",
       "      <td>subsidiary (P355)</td>\n",
       "      <td>SM Life Design Group (Q107473707)</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8353</th>\n",
       "      <td>sm_entertainment</td>\n",
       "      <td>subsidiary (P355)</td>\n",
       "      <td>Mystic Story (Q15509774)</td>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8354 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           head_entity           relation  \\\n",
       "0           apple_inc.   owner of (P1830)   \n",
       "1           apple_inc.   owner of (P1830)   \n",
       "2           apple_inc.  subsidiary (P355)   \n",
       "3           apple_inc.  subsidiary (P355)   \n",
       "4           apple_inc.  subsidiary (P355)   \n",
       "...                ...                ...   \n",
       "8349  sm_entertainment  subsidiary (P355)   \n",
       "8350  sm_entertainment  subsidiary (P355)   \n",
       "8351  sm_entertainment  subsidiary (P355)   \n",
       "8352  sm_entertainment  subsidiary (P355)   \n",
       "8353  sm_entertainment  subsidiary (P355)   \n",
       "\n",
       "                               tail_entity            start_date end_date  \n",
       "0      Imagination Technologies (Q1119662)  2018-01-01T00:00:00Z     None  \n",
       "1     Apple corporate shuttle (Q110553619)  2018-01-01T00:00:00Z     None  \n",
       "2               FileMaker, Inc. (Q1982831)  2018-01-01T00:00:00Z     None  \n",
       "3                        Anobit (Q2893391)  2018-01-01T00:00:00Z     None  \n",
       "4             Beats Electronics (Q1961036)  2018-01-01T00:00:00Z     None  \n",
       "...                                    ...                   ...      ...  \n",
       "8349              SM Classics (Q105753127)  2018-01-01T00:00:00Z     None  \n",
       "8350                  Label V (Q107463954)  2018-01-01T00:00:00Z     None  \n",
       "8351                  Baljunso (Q18159635)  2018-01-01T00:00:00Z     None  \n",
       "8352     SM Life Design Group (Q107473707)  2018-01-01T00:00:00Z     None  \n",
       "8353              Mystic Story (Q15509774)  2018-01-01T00:00:00Z     None  \n",
       "\n",
       "[8354 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tkg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf592f",
   "metadata": {},
   "source": [
    "### News Articles (and check if sentences are in the correct relation and time order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94add5c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence_df = pd.read_csv(data_path + 'new_sentence_df_0509.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccafedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_df['tuples'] = sentence_df['tuples'].apply(lambda x: ast.literal_eval(x))\n",
    "# sentence_df['publishedAt'] = sentence_df['publishedAt'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48def289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if relation and time ordering is correct in sentence_df\n",
    "# sentence_df.drop_duplicates('tuples', inplace = True)\n",
    "# tuples_index_2018_df = sentence_df.set_index(['tuples'])\n",
    "# sorted_df = tuples_index_2018_df.sort_values('publishedAt')\n",
    "# sorted_df.index.nunique()\n",
    "\n",
    "# relation_ordering = {\n",
    "#     'considering': 1,\n",
    "#     'expecting': 2,\n",
    "#     'success': 3,\n",
    "#     'terminated': 4\n",
    "# }\n",
    "\n",
    "# def check_relation_ordering(dataframe, relation_order = relation_ordering):\n",
    "#     current = 0\n",
    "#     for indx in dataframe.index:\n",
    "#         relation = indx[1].split('_')[0]\n",
    "#         if relation_order[relation] > current:\n",
    "#             current = relation_order[relation]\n",
    "#         else:\n",
    "#             return False\n",
    "#     return True\n",
    "\n",
    "# def check_time_ordering(dataframe):\n",
    "#     latest_date = None\n",
    "#     for idx, item in enumerate(dataframe['publishedAt']):\n",
    "#         if latest_date == None:\n",
    "#             latest_date = item\n",
    "#         elif item < latest_date:\n",
    "#             return False\n",
    "#         elif item >= latest_date:\n",
    "#             latest_date = item\n",
    "#     return True\n",
    "\n",
    "# res = []\n",
    "# for i in tuples_index_2018_df['final_company_deal'].unique():\n",
    "#     temp_df = tuples_index_2018_df[tuples_index_2018_df['final_company_deal'] == i]\n",
    "#     if not check_relation_ordering(temp_df):\n",
    "#         res.append((i, False))\n",
    "#     else:\n",
    "#         res.append((i, True))\n",
    "        \n",
    "# time_res = []\n",
    "# for i in tuples_index_2018_df['final_company_deal'].unique():\n",
    "#     temp_df = tuples_index_2018_df[tuples_index_2018_df['final_company_deal'] == i]\n",
    "#     if not check_time_ordering(temp_df):\n",
    "#         time_res.append((i, False))\n",
    "#     else:\n",
    "#         time_res.append((i, True))\n",
    "        \n",
    "# relation_res_df = pd.DataFrame(res)\n",
    "# time_res_df = pd.DataFrame(time_res)\n",
    "\n",
    "# print(relation_res_df[1].value_counts())\n",
    "# print(time_res_df[1].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa308a",
   "metadata": {},
   "source": [
    "### Parse each document now from sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f79b39ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tuples</th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>relation</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>merger_or_acq</th>\n",
       "      <th>keywords</th>\n",
       "      <th>mentions</th>\n",
       "      <th>relations</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>...</th>\n",
       "      <th>final_company_deal</th>\n",
       "      <th>general_questions</th>\n",
       "      <th>head_questions</th>\n",
       "      <th>tail_questions</th>\n",
       "      <th>new_general_questions</th>\n",
       "      <th>new_head_questions</th>\n",
       "      <th>new_tail_questions</th>\n",
       "      <th>latest_general_questions</th>\n",
       "      <th>latest_head_questions</th>\n",
       "      <th>latest_tail_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('apple_inc.', 'considering_acq', 'netflix', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>There is a 40% likelihood that Apple will acqu...</td>\n",
       "      <td>considering_acq</td>\n",
       "      <td>2018-01-01 09:04:47</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquire</td>\n",
       "      <td>[('Citi', 'Org'), ('Apple', 'Bidder'), ('Netfl...</td>\n",
       "      <td>['40% likelihood']</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>apple_inc._netflix</td>\n",
       "      <td>((\"What's the deal between apple_inc. and netf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"What's the deal between apple_inc. and netf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('prestige_group', 'success_acq', 'capitaland'...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NEW DELHI: Realty firm Prestige group today sa...</td>\n",
       "      <td>success_acq</td>\n",
       "      <td>2018-01-01 12:46:26</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquire</td>\n",
       "      <td>[('Prestige group', 'Bidder'), ('it will acqui...</td>\n",
       "      <td>['it will acquire']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>prestige_group_capitaland</td>\n",
       "      <td>((\"What's the deal between prestige_group and ...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between prestige_group and ...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('bd_(company)', 'success_acq', 'bard', '2018-...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Under the terms of the transaction, upon compl...</td>\n",
       "      <td>success_acq</td>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>[('Bard', 'Target'), ('Bard', 'Target'), ('BD'...</td>\n",
       "      <td>['upon completion of the acquisition']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>bd_(company)_bard</td>\n",
       "      <td>((\"What's the deal between bd_(company) and ba...</td>\n",
       "      <td>{'before': [('Who does FlowJo LLC (Q106573956)...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between bd_(company) and ba...</td>\n",
       "      <td>{'before': [('Who does FlowJo LLC (Q106573956)...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>{'before': [('Who does FlowJo LLC (Q106573956)...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('bhi', 'success_merger', 'marcventure', '2018...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Marcventure said the merger with BHI will enab...</td>\n",
       "      <td>success_merger</td>\n",
       "      <td>2018-01-02 09:09:57</td>\n",
       "      <td>Merger</td>\n",
       "      <td>merger</td>\n",
       "      <td>[('BHI', 'Bidder'), ('Marcventure', 'Bidder'),...</td>\n",
       "      <td>['merger']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>bhi_marcventure</td>\n",
       "      <td>((\"What's the deal between bhi and marcventure...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between bhi and marcventure...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the first bidder of the merger deal o...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('h.j. heinz', 'success_merger', 'kraft_foods'...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>For two years, investors and other stakeholder...</td>\n",
       "      <td>success_merger</td>\n",
       "      <td>2018-01-02 10:15:00</td>\n",
       "      <td>Merger</td>\n",
       "      <td>merger</td>\n",
       "      <td>[('Kraft Heinz', 'Org'), ('H.J. Heinz', 'Bidde...</td>\n",
       "      <td>['created through the $46 billion merger']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>h.j. heinz_kraft_foods</td>\n",
       "      <td>((\"What's the deal between h.j. heinz and kraf...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [('Who owns Kool-Aid (Q1531983) bef...</td>\n",
       "      <td>[(\"What's the deal between h.j. heinz and kraf...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [('Who owns Kool-Aid (Q1531983) bef...</td>\n",
       "      <td>[(\"Who's the first bidder of the merger deal o...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [('Who owns Kool-Aid (Q1531983) bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>('tervita corporation', 'expecting_merger', 't...</td>\n",
       "      <td>53598.0</td>\n",
       "      <td>(\"SECURE\") (TSX: SES) and Tervita Corporation ...</td>\n",
       "      <td>expecting_merger</td>\n",
       "      <td>2021-06-30 06:17:00</td>\n",
       "      <td>Merger</td>\n",
       "      <td>merger</td>\n",
       "      <td>[('Tervita Corporation', 'Bidder'), ('TSX', 'O...</td>\n",
       "      <td>['proposed merger']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>tervita corporation_tervita</td>\n",
       "      <td>((\"What's the deal between tervita corporation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"What's the deal between tervita corporation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"Who's the first bidder of the merger deal o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>('american_lithium_energy_(united_states)', 's...</td>\n",
       "      <td>53613.0</td>\n",
       "      <td>(American Lithium or the Company) (TSX-V: LI |...</td>\n",
       "      <td>success_merger</td>\n",
       "      <td>2021-06-30 11:00:00</td>\n",
       "      <td>Merger</td>\n",
       "      <td>merger</td>\n",
       "      <td>[('American Lithium', 'Bidder'), ('OTCQB', 'Or...</td>\n",
       "      <td>['recent merger']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>american_lithium_energy_(united_states)_platea...</td>\n",
       "      <td>((\"What's the deal between american_lithium_en...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between american_lithium_en...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the first bidder of the merger deal o...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>('nxlv', 'success_acq', 'nexliving', '2021-06-...</td>\n",
       "      <td>53632.0</td>\n",
       "      <td>(TSXV: NXLV) (\"NexLiving\" or the \"Company\") an...</td>\n",
       "      <td>success_acq</td>\n",
       "      <td>2021-06-30 14:00:00</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>[('TSXV', 'Org'), ('NXLV', 'Bidder'), ('NexLiv...</td>\n",
       "      <td>['completed', 'acquisition']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>nxlv_nexliving</td>\n",
       "      <td>((\"What's the deal between nxlv and nexliving ...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between nxlv and nexliving ...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>('nuevopak', 'success_acq', 'nuevopak global l...</td>\n",
       "      <td>53636.0</td>\n",
       "      <td>) it has entered into a definitive agreement t...</td>\n",
       "      <td>success_acq</td>\n",
       "      <td>2021-06-30 14:20:36</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquire</td>\n",
       "      <td>[('entered into a definitive agreement to', 's...</td>\n",
       "      <td>['entered into a definitive agreement to']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>nuevopak_nuevopak global limited</td>\n",
       "      <td>((\"What's the deal between nuevopak and nuevop...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between nuevopak and nuevop...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>('microsoft', 'expecting_acq', 'at&amp;amp;ts', '2...</td>\n",
       "      <td>53644.0</td>\n",
       "      <td>Microsoft announced that it will acquire AT&amp;am...</td>\n",
       "      <td>expecting_acq</td>\n",
       "      <td>2021-06-30 15:12:32</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquire</td>\n",
       "      <td>[('Microsoft', 'Bidder'), ('will acquire', 'ex...</td>\n",
       "      <td>['will acquire']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>microsoft_at&amp;amp;ts</td>\n",
       "      <td>((\"What's the deal between microsoft and at&amp;am...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"What's the deal between microsoft and at&amp;am...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5721 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tuples  article_id  \\\n",
       "0     ('apple_inc.', 'considering_acq', 'netflix', '...         1.0   \n",
       "1     ('prestige_group', 'success_acq', 'capitaland'...         2.0   \n",
       "2     ('bd_(company)', 'success_acq', 'bard', '2018-...         5.0   \n",
       "3     ('bhi', 'success_merger', 'marcventure', '2018...        19.0   \n",
       "4     ('h.j. heinz', 'success_merger', 'kraft_foods'...        22.0   \n",
       "...                                                 ...         ...   \n",
       "5716  ('tervita corporation', 'expecting_merger', 't...     53598.0   \n",
       "5717  ('american_lithium_energy_(united_states)', 's...     53613.0   \n",
       "5718  ('nxlv', 'success_acq', 'nexliving', '2021-06-...     53632.0   \n",
       "5719  ('nuevopak', 'success_acq', 'nuevopak global l...     53636.0   \n",
       "5720  ('microsoft', 'expecting_acq', 'at&amp;ts', '2...     53644.0   \n",
       "\n",
       "                                              sentences          relation  \\\n",
       "0     There is a 40% likelihood that Apple will acqu...   considering_acq   \n",
       "1     NEW DELHI: Realty firm Prestige group today sa...       success_acq   \n",
       "2     Under the terms of the transaction, upon compl...       success_acq   \n",
       "3     Marcventure said the merger with BHI will enab...    success_merger   \n",
       "4     For two years, investors and other stakeholder...    success_merger   \n",
       "...                                                 ...               ...   \n",
       "5716  (\"SECURE\") (TSX: SES) and Tervita Corporation ...  expecting_merger   \n",
       "5717  (American Lithium or the Company) (TSX-V: LI |...    success_merger   \n",
       "5718  (TSXV: NXLV) (\"NexLiving\" or the \"Company\") an...       success_acq   \n",
       "5719  ) it has entered into a definitive agreement t...       success_acq   \n",
       "5720  Microsoft announced that it will acquire AT&am...     expecting_acq   \n",
       "\n",
       "              publishedAt merger_or_acq     keywords  \\\n",
       "0     2018-01-01 09:04:47           Acq      acquire   \n",
       "1     2018-01-01 12:46:26           Acq      acquire   \n",
       "2     2018-01-02 00:00:00           Acq  acquisition   \n",
       "3     2018-01-02 09:09:57        Merger       merger   \n",
       "4     2018-01-02 10:15:00        Merger       merger   \n",
       "...                   ...           ...          ...   \n",
       "5716  2021-06-30 06:17:00        Merger       merger   \n",
       "5717  2021-06-30 11:00:00        Merger       merger   \n",
       "5718  2021-06-30 14:00:00           Acq  acquisition   \n",
       "5719  2021-06-30 14:20:36           Acq      acquire   \n",
       "5720  2021-06-30 15:12:32           Acq      acquire   \n",
       "\n",
       "                                               mentions  \\\n",
       "0     [('Citi', 'Org'), ('Apple', 'Bidder'), ('Netfl...   \n",
       "1     [('Prestige group', 'Bidder'), ('it will acqui...   \n",
       "2     [('Bard', 'Target'), ('Bard', 'Target'), ('BD'...   \n",
       "3     [('BHI', 'Bidder'), ('Marcventure', 'Bidder'),...   \n",
       "4     [('Kraft Heinz', 'Org'), ('H.J. Heinz', 'Bidde...   \n",
       "...                                                 ...   \n",
       "5716  [('Tervita Corporation', 'Bidder'), ('TSX', 'O...   \n",
       "5717  [('American Lithium', 'Bidder'), ('OTCQB', 'Or...   \n",
       "5718  [('TSXV', 'Org'), ('NXLV', 'Bidder'), ('NexLiv...   \n",
       "5719  [('entered into a definitive agreement to', 's...   \n",
       "5720  [('Microsoft', 'Bidder'), ('will acquire', 'ex...   \n",
       "\n",
       "                                       relations  wikidata  ...  \\\n",
       "0                             ['40% likelihood']      True  ...   \n",
       "1                            ['it will acquire']     False  ...   \n",
       "2         ['upon completion of the acquisition']     False  ...   \n",
       "3                                     ['merger']     False  ...   \n",
       "4     ['created through the $46 billion merger']     False  ...   \n",
       "...                                          ...       ...  ...   \n",
       "5716                         ['proposed merger']     False  ...   \n",
       "5717                           ['recent merger']     False  ...   \n",
       "5718                ['completed', 'acquisition']     False  ...   \n",
       "5719  ['entered into a definitive agreement to']     False  ...   \n",
       "5720                            ['will acquire']     False  ...   \n",
       "\n",
       "                                     final_company_deal  \\\n",
       "0                                    apple_inc._netflix   \n",
       "1                             prestige_group_capitaland   \n",
       "2                                     bd_(company)_bard   \n",
       "3                                       bhi_marcventure   \n",
       "4                                h.j. heinz_kraft_foods   \n",
       "...                                                 ...   \n",
       "5716                        tervita corporation_tervita   \n",
       "5717  american_lithium_energy_(united_states)_platea...   \n",
       "5718                                     nxlv_nexliving   \n",
       "5719                   nuevopak_nuevopak global limited   \n",
       "5720                                microsoft_at&amp;ts   \n",
       "\n",
       "                                      general_questions  \\\n",
       "0     ((\"What's the deal between apple_inc. and netf...   \n",
       "1     ((\"What's the deal between prestige_group and ...   \n",
       "2     ((\"What's the deal between bd_(company) and ba...   \n",
       "3     ((\"What's the deal between bhi and marcventure...   \n",
       "4     ((\"What's the deal between h.j. heinz and kraf...   \n",
       "...                                                 ...   \n",
       "5716  ((\"What's the deal between tervita corporation...   \n",
       "5717  ((\"What's the deal between american_lithium_en...   \n",
       "5718  ((\"What's the deal between nxlv and nexliving ...   \n",
       "5719  ((\"What's the deal between nuevopak and nuevop...   \n",
       "5720  ((\"What's the deal between microsoft and at&am...   \n",
       "\n",
       "                                         head_questions  \\\n",
       "0                                                   NaN   \n",
       "1                           {'before': [], 'after': []}   \n",
       "2     {'before': [('Who does FlowJo LLC (Q106573956)...   \n",
       "3                           {'before': [], 'after': []}   \n",
       "4                           {'before': [], 'after': []}   \n",
       "...                                                 ...   \n",
       "5716                                                NaN   \n",
       "5717                        {'before': [], 'after': []}   \n",
       "5718                        {'before': [], 'after': []}   \n",
       "5719                        {'before': [], 'after': []}   \n",
       "5720                                                NaN   \n",
       "\n",
       "                                         tail_questions  \\\n",
       "0                                                   NaN   \n",
       "1                           {'before': [], 'after': []}   \n",
       "2                           {'before': [], 'after': []}   \n",
       "3                           {'before': [], 'after': []}   \n",
       "4     {'before': [('Who owns Kool-Aid (Q1531983) bef...   \n",
       "...                                                 ...   \n",
       "5716                                                NaN   \n",
       "5717                        {'before': [], 'after': []}   \n",
       "5718                        {'before': [], 'after': []}   \n",
       "5719                        {'before': [], 'after': []}   \n",
       "5720                                                NaN   \n",
       "\n",
       "                                  new_general_questions  \\\n",
       "0     [(\"What's the deal between apple_inc. and netf...   \n",
       "1     [(\"What's the deal between prestige_group and ...   \n",
       "2     [(\"What's the deal between bd_(company) and ba...   \n",
       "3     [(\"What's the deal between bhi and marcventure...   \n",
       "4     [(\"What's the deal between h.j. heinz and kraf...   \n",
       "...                                                 ...   \n",
       "5716  [(\"What's the deal between tervita corporation...   \n",
       "5717  [(\"What's the deal between american_lithium_en...   \n",
       "5718  [(\"What's the deal between nxlv and nexliving ...   \n",
       "5719  [(\"What's the deal between nuevopak and nuevop...   \n",
       "5720  [(\"What's the deal between microsoft and at&am...   \n",
       "\n",
       "                                     new_head_questions  \\\n",
       "0                                                   NaN   \n",
       "1                           {'before': [], 'after': []}   \n",
       "2     {'before': [('Who does FlowJo LLC (Q106573956)...   \n",
       "3                           {'before': [], 'after': []}   \n",
       "4                           {'before': [], 'after': []}   \n",
       "...                                                 ...   \n",
       "5716                                                NaN   \n",
       "5717                        {'before': [], 'after': []}   \n",
       "5718                        {'before': [], 'after': []}   \n",
       "5719                        {'before': [], 'after': []}   \n",
       "5720                                                NaN   \n",
       "\n",
       "                                     new_tail_questions  \\\n",
       "0                                                   NaN   \n",
       "1                           {'before': [], 'after': []}   \n",
       "2                           {'before': [], 'after': []}   \n",
       "3                           {'before': [], 'after': []}   \n",
       "4     {'before': [('Who owns Kool-Aid (Q1531983) bef...   \n",
       "...                                                 ...   \n",
       "5716                                                NaN   \n",
       "5717                        {'before': [], 'after': []}   \n",
       "5718                        {'before': [], 'after': []}   \n",
       "5719                        {'before': [], 'after': []}   \n",
       "5720                                                NaN   \n",
       "\n",
       "                               latest_general_questions  \\\n",
       "0     [(\"Who's the bidder of the acquisition deal on...   \n",
       "1     [(\"Who's the bidder of the acquisition deal on...   \n",
       "2     [(\"Who's the bidder of the acquisition deal on...   \n",
       "3     [(\"Who's the first bidder of the merger deal o...   \n",
       "4     [(\"Who's the first bidder of the merger deal o...   \n",
       "...                                                 ...   \n",
       "5716  [(\"Who's the first bidder of the merger deal o...   \n",
       "5717  [(\"Who's the first bidder of the merger deal o...   \n",
       "5718  [(\"Who's the bidder of the acquisition deal on...   \n",
       "5719  [(\"Who's the bidder of the acquisition deal on...   \n",
       "5720  [(\"Who's the bidder of the acquisition deal on...   \n",
       "\n",
       "                                  latest_head_questions  \\\n",
       "0                                                   NaN   \n",
       "1                           {'before': [], 'after': []}   \n",
       "2     {'before': [('Who does FlowJo LLC (Q106573956)...   \n",
       "3                           {'before': [], 'after': []}   \n",
       "4                           {'before': [], 'after': []}   \n",
       "...                                                 ...   \n",
       "5716                                                NaN   \n",
       "5717                        {'before': [], 'after': []}   \n",
       "5718                        {'before': [], 'after': []}   \n",
       "5719                        {'before': [], 'after': []}   \n",
       "5720                                                NaN   \n",
       "\n",
       "                                  latest_tail_questions  \n",
       "0                                                   NaN  \n",
       "1                           {'before': [], 'after': []}  \n",
       "2                           {'before': [], 'after': []}  \n",
       "3                           {'before': [], 'after': []}  \n",
       "4     {'before': [('Who owns Kool-Aid (Q1531983) bef...  \n",
       "...                                                 ...  \n",
       "5716                                                NaN  \n",
       "5717                        {'before': [], 'after': []}  \n",
       "5718                        {'before': [], 'after': []}  \n",
       "5719                        {'before': [], 'after': []}  \n",
       "5720                                                NaN  \n",
       "\n",
       "[5721 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ddfb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_common_entities(tuple_list1, tuple_list2):\n",
    "    entities_list1 = [i[2] for i in tuple_list1]\n",
    "    entities_list2 = [i[2] for i in tuple_list2]\n",
    "    \n",
    "    list1_as_set = set(entities_list1)\n",
    "    intersection = list1_as_set.intersection(entities_list2)\n",
    "\n",
    "    intersection_as_list = list(intersection)\n",
    "\n",
    "    return intersection_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "728113e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "all_tkg_snapshots = [tkg_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "503b9aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentence_df)):\n",
    "    data = sentence_df.iloc[i]\n",
    "    head_entity = data['lowered_head']\n",
    "    relation_word, deal = data['relation'].split('_')[0], data['relation'].split('_')[1]\n",
    "    tail_entity = data['lowered_tail']\n",
    "    date = data['publishedAt'].split(\" \")\n",
    "    date = date[0] + 'T' + date[1] + 'Z'\n",
    "    quad = (head_entity, data['relation'], tail_entity, date)\n",
    "    \n",
    "    latest_dict = copy.deepcopy(all_tkg_snapshots[-1])\n",
    "    \n",
    "    try:\n",
    "        head_data = latest_dict[head_entity]\n",
    "        tail_data = latest_dict[tail_entity]\n",
    "    except:\n",
    "        if head_entity not in latest_dict.keys():\n",
    "            latest_dict[head_entity] = []\n",
    "\n",
    "        if tail_entity not in latest_dict.keys():\n",
    "            latest_dict[tail_entity] = []\n",
    "        \n",
    "        head_data = latest_dict[head_entity]\n",
    "        tail_data = latest_dict[tail_entity]\n",
    "    \n",
    "    common_entities = return_common_entities(head_data, tail_data)\n",
    "    \n",
    "    new_head_tuples = []\n",
    "    new_tail_tuples = []\n",
    "    to_be_remove_tuples = []\n",
    "    if relation_word == 'success':\n",
    "        if deal == 'acq':\n",
    "            # success_acq\n",
    "            for d in tail_data:\n",
    "                if d[1] == 'owner of (P1830)' or d[1] == 'subsidiary (P355)' or d[1] == 'business division (P199)':\n",
    "                    # the head_entity now acquires certain assets of the tail and new quads are being added\n",
    "                    new_tuple = (head_entity, d[1], d[2], date)\n",
    "                    new_head_tuples.append(new_tuple)\n",
    "\n",
    "                    # the tail entity is being acquired so all tuples now include an end date\n",
    "                    end_tuple = d + (date,)\n",
    "                    new_tail_tuples.append(end_tuple)\n",
    "                    to_be_remove_tuples.append(d)\n",
    "                elif d[1] == 'board member (P3320)' or d[1] == 'owned by (P127)':\n",
    "                    if not d[2] in common_entities:\n",
    "                        # the tail entity is being acquired so all tuples now include an end date\n",
    "                        end_tuple = d + (date,)\n",
    "                        new_tail_tuples.append(end_tuple)\n",
    "                        to_be_remove_tuples.append(d)\n",
    "\n",
    "            for h in head_data:\n",
    "                # the tail entity is being acquired so all the board member and owned by values now own the tail entity\n",
    "                if h[1] == 'board member (P3320)' or h[1] == 'owned by (P127)':\n",
    "                    new_tuple = (tail_entity, h[1], h[2], date)\n",
    "                    new_tail_tuples.append(new_tuple)\n",
    "                    \n",
    "                if h[2] == tail_entity and len(h) == 4: # length 4 means only has start date and no end date:\n",
    "                    end_tuple = h + (date,)\n",
    "                    new_head_tuples.append(end_tuple)\n",
    "                    to_be_remove_tuples.append(h)\n",
    "        elif deal == 'merger':\n",
    "            # success_merger            \n",
    "            for h in head_data:\n",
    "                if h[2] == tail_entity and len(h) == 4: # length 4 means only has start date and no end date\n",
    "                    end_tuple = h + (date,)\n",
    "                    new_head_tuples.append(end_tuple)\n",
    "                    to_be_remove_tuples.append(h)\n",
    "    else:\n",
    "        # all other relations\n",
    "        for h in head_data:\n",
    "            if h[2] == tail_entity and len(h) == 4: # length 4 means only has start date and no end date\n",
    "                end_tuple = h + (date,)\n",
    "                new_head_tuples.append(end_tuple)\n",
    "                to_be_remove_tuples.append(h)\n",
    "    \n",
    "    # remove outdated tuples\n",
    "    for z in to_be_remove_tuples:\n",
    "        try:\n",
    "            latest_dict[tail_entity].remove(z)\n",
    "        except:\n",
    "            latest_dict[head_entity].remove(z)\n",
    "\n",
    "    # add new tuples\n",
    "    latest_dict[head_entity].append(quad)\n",
    "    latest_dict[head_entity] = latest_dict[head_entity] + new_head_tuples\n",
    "    latest_dict[tail_entity] = latest_dict[tail_entity] + new_tail_tuples\n",
    "    \n",
    "    all_tkg_snapshots.append(latest_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "709b3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_size_tkg_dict(snapshot_tkg):\n",
    "    emp_length = 0\n",
    "    for x in snapshot_tkg.values():\n",
    "        if isinstance(x, list):\n",
    "            emp_length += len(x)\n",
    "    \n",
    "    return emp_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09d453",
   "metadata": {},
   "source": [
    "### Compute differences between snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdc20e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdiff import DeepDiff\n",
    "\n",
    "all_differences = []\n",
    "for i in range(len(all_tkg_snapshots)):\n",
    "    if i == 0:\n",
    "        all_differences.append({})\n",
    "        continue\n",
    "    \n",
    "    previous_tkg_snapshot = all_tkg_snapshots[i - 1]\n",
    "    latest_tkg_snapshot = all_tkg_snapshots[i]\n",
    "    \n",
    "    all_differences.append(DeepDiff(previous_tkg_snapshot, latest_tkg_snapshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18157a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_differences = all_differences[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75130a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tkg = all_tkg_snapshots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c05da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_tkg_snapshots = [cal_size_tkg_dict(i) for i in all_tkg_snapshots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0825b802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5722"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tkg_snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c4713a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5722"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(len_tkg_snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb0823e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5721"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b1b6be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5721"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e1245",
   "metadata": {},
   "source": [
    "### Flatten dictionary and convert to ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "790e8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(dictionary):\n",
    "    res = []\n",
    "    for key, value in dictionary.items():\n",
    "        res += value\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32eac4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_none_tuples(list_of_tuples):\n",
    "    for item in list_of_tuples:\n",
    "        if type(item[2]) == type(None) or type(item[0]) == type(None) or type(item[1]) == type(None) or type(item[3]) == type(None):\n",
    "            list_of_tuples.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9056453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_all_tkg_snapshots = [flatten_dict(x) for x in all_tkg_snapshots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cc0b4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8354"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten_all_tkg_snapshots[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f922357",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_all_tkg_snapshots = [remove_none_tuples(x) for x in flatten_all_tkg_snapshots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b272029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8319"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten_all_tkg_snapshots[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eecaa93a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence_df['before_tkg'] = flatten_all_tkg_snapshots[:5721]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2be7089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df['after_tkg'] = flatten_all_tkg_snapshots[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42383218",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df['differences'] = all_differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6fb974",
   "metadata": {},
   "source": [
    "### Create ent_id, rel_id, and ts_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d67ddba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ent_rel_ts_id_at_t(tkg_snapshot):\n",
    "    tuples_at_t = []\n",
    "    for key, item in tkg_snapshot.items():\n",
    "        tuples_at_t.append(item)\n",
    "    flat_list = [item for sublist in tuples_at_t for item in sublist]\n",
    "\n",
    "    try:\n",
    "        t_state_tkg = pd.DataFrame(flat_list, columns=['head_entity', 'relation', 'tail_entity', 'start_date', 'end_date'])\n",
    "    except:\n",
    "        t_state_tkg = pd.DataFrame(flat_list, columns=['head_entity', 'relation', 'tail_entity', 'start_date'])\n",
    "        t_state_tkg['end_date'] = None\n",
    "    \n",
    "    def creating_time_point(dataframe):\n",
    "        res = []\n",
    "        for i in range(len(dataframe)):\n",
    "            if pd.isna(dataframe['end_date'][i]):\n",
    "                res.append('2021-07-01T00:00:00+00:00Z')\n",
    "            else:\n",
    "                res.append(dataframe['end_date'][i])\n",
    "\n",
    "        return res\n",
    "    \n",
    "    t_state_tkg['new_end_date'] = creating_time_point(t_state_tkg)\n",
    "    t_state_tkg['time_point_de'] = t_state_tkg['new_end_date'].apply(lambda x: x.split('T')[0])\n",
    "    \n",
    "    entities, relations = set(), set()\n",
    "    for i in range(len(t_state_tkg)):\n",
    "        data = t_state_tkg.iloc[i]\n",
    "        head_entity = data['head_entity']\n",
    "        tail_entity = data['tail_entity']\n",
    "        relation = data['relation']\n",
    "\n",
    "        entities.add(head_entity)\n",
    "        entities.add(tail_entity)\n",
    "        relations.add(relation)\n",
    "        \n",
    "    entities.remove(None)\n",
    "    entities.add('ANSWER HOLDER')\n",
    "    \n",
    "    a = list(t_state_tkg['start_date']) + list(t_state_tkg['new_end_date'])\n",
    "    b = [x.split('T')[0] for x in a]\n",
    "    c = list(set(b))\n",
    "    c.sort()\n",
    "    ts_res = []\n",
    "    for x in c:\n",
    "        date_split = x.split('-')\n",
    "        ts_res.append((int(date_split[0]), int(date_split[1]), int(date_split[2])))\n",
    "    \n",
    "    entities_to_id = {x: i for (i, x) in enumerate(sorted(entities))}\n",
    "    relations_to_id = {x: i for (i, x) in enumerate(sorted(relations))}\n",
    "    timestamps_to_id = {x: i for (i, x) in enumerate(ts_res)}\n",
    "    \n",
    "    return entities_to_id, relations_to_id, timestamps_to_id, t_state_tkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "14ec8d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_results = []\n",
    "for snap in all_tkg_snapshots:\n",
    "    res = {}\n",
    "    ent, rel, ts, df = create_ent_rel_ts_id_at_t(snap)\n",
    "    res['ent_id'] = ent\n",
    "    res['rel_id'] = rel\n",
    "    res['ts_id'] = ts\n",
    "    id_results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3cb08f20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5722"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01bb3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7742d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tuples = []\n",
    "for key, item in all_tkg_snapshots[-1].items():\n",
    "    all_tuples.append(item)\n",
    "flat_list = [item for sublist in all_tuples for item in sublist]\n",
    "\n",
    "last_state_tkg = pd.DataFrame(flat_list, columns=['head_entity', 'relation', 'tail_entity', 'start_date', 'end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6db4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities, relations = set(), set()\n",
    "for i in range(len(last_state_tkg)):\n",
    "    data = last_state_tkg.iloc[i]\n",
    "    head_entity = data['head_entity']\n",
    "    tail_entity = data['tail_entity']\n",
    "    relation = data['relation']\n",
    "    \n",
    "    entities.add(head_entity)\n",
    "    entities.add(tail_entity)\n",
    "    relations.add(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21abf87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14757"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a427af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.remove(None)\n",
    "entities.add('ANSWER HOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0668b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14757"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f84ace60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6aa341ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range('2018-01-01', periods=(1278.5), freq='1D')\n",
    "string_dates = [x.strftime('%Y-%m-%d') for x in times]\n",
    "\n",
    "ts_res = []\n",
    "for x in string_dates:\n",
    "    date_split = x.split('-')\n",
    "    ts_res.append((int(date_split[0]), int(date_split[1]), int(date_split[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79c5ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_to_id = {x: i for (i, x) in enumerate(sorted(entities))}\n",
    "relations_to_id = {x: i for (i, x) in enumerate(sorted(relations))}\n",
    "timestamps_to_id = {x: i for (i, x) in enumerate(ts_res)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e84863d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "for (dic, f) in zip([entities_to_id, relations_to_id, timestamps_to_id], ['ent_id_1010', 'rel_id_1010', 'ts_id_1010']):\n",
    "    ff = open(os.path.join(data_path, f), 'wb')\n",
    "    pickle.dump(dic, ff)\n",
    "    ff.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b455a3ec",
   "metadata": {},
   "source": [
    "### Prepare data for update process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbef4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dicts = {}\n",
    "for f in ['ent_id_1010', 'rel_id_1010', 'ts_id_1010']:\n",
    "    in_file = open(str(data_path + f), 'rb')\n",
    "    dicts[f] = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c542f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df['latest_general_questions'] = sentence_df['latest_general_questions'].apply(lambda x: ast.literal_eval(x) if type(x) == type(\"string\") else x)\n",
    "sentence_df['latest_head_questions'] = sentence_df['latest_head_questions'].apply(lambda x: ast.literal_eval(x) if type(x) == type(\"string\") else x)\n",
    "sentence_df['latest_tail_questions'] = sentence_df['latest_tail_questions'].apply(lambda x: ast.literal_eval(x) if type(x) == type(\"string\") else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9b8ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_tkg(list_tkg):\n",
    "    quad_ids = []\n",
    "    for x in list_tkg:\n",
    "        head_id = dicts['ent_id_1010'][x[0]]\n",
    "        relation_id = dicts['rel_id_1010'][x[1]]\n",
    "        tail_id = dicts['ent_id_1010'][x[2]]\n",
    "        date_split = x[3].split('T')[0].split('-')\n",
    "        date_id = dicts['ts_id_1010'][(int(date_split[0]), int(date_split[1]), int(date_split[2]))]\n",
    "\n",
    "        try:\n",
    "            end_date_split = x[4].split('T')[0].split('-')\n",
    "            end_date_id = dicts['ts_id_1010'][(int(end_date_split[0]), int(end_date_split[1]), int(end_date_split[2]))]\n",
    "        except:\n",
    "            end_date_id = dicts['ts_id_1010'][(2021, 7, 1)]\n",
    "\n",
    "\n",
    "        quad_id = (head_id, relation_id, tail_id, date_id, end_date_id)\n",
    "        \n",
    "        quad_ids.append(quad_id)\n",
    "    \n",
    "    return quad_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ab04631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datapoints(row):\n",
    "    event_date = row['publishedAt']\n",
    "\n",
    "    before_tkg = row['before_tkg']\n",
    "    after_tkg = row['after_tkg']\n",
    "    differences = row['differences']\n",
    "\n",
    "    if type(row['latest_head_questions']) == float:\n",
    "        before_head_questions = row['latest_head_questions']\n",
    "        after_head_questions = row['latest_head_questions']\n",
    "    else:\n",
    "        before_head_questions = row['latest_head_questions']['before']\n",
    "        after_head_questions = row['latest_head_questions']['after']\n",
    "\n",
    "    if type(row['latest_tail_questions']) == float:\n",
    "        before_tail_questions = row['latest_tail_questions']\n",
    "        after_tail_questions = row['latest_tail_questions']\n",
    "    else:\n",
    "        before_tail_questions = row['latest_tail_questions']['before']\n",
    "        after_tail_questions = row['latest_tail_questions']['after']\n",
    "\n",
    "    return {\n",
    "        'article_id': row['article_id'],\n",
    "        'sentence_text': row['sentences'],\n",
    "        'tuples': row['tuples'],\n",
    "        'entities': ast.literal_eval(row['companies_deal']),\n",
    "        'relations': row['relation'],\n",
    "        'date': event_date,\n",
    "#         'before_tkg': encoding_tkg(before_tkg),\n",
    "#         'after_tkg': encoding_tkg(after_tkg),\n",
    "        'before_tkg': before_tkg,\n",
    "        'after_tkg': after_tkg,\n",
    "        'differences_tkg': str(differences),\n",
    "        'general_questions': row['latest_general_questions'],\n",
    "        'before_head_questions': before_head_questions,\n",
    "        'before_tail_questions': before_tail_questions,\n",
    "        'after_head_questions': after_head_questions,\n",
    "        'after_tail_questions': after_tail_questions,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f6533ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for index, row in sentence_df.iterrows():\n",
    "    all_data.append(prepare_datapoints(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a686771",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[:4633]\n",
    "val = all_data[4633:5148]\n",
    "test = all_data[5148:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4daf0f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_split, test_data  = train_test_split(sentence_df, train_size=0.9)\n",
    "train_data, val_data = train_test_split(train_val_split, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c185a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4633"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9cf336f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34e45c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f0f52c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "for index, row in train_data.iterrows():\n",
    "    train.append(prepare_datapoints(row))\n",
    "\n",
    "val = []\n",
    "for index, row in val_data.iterrows():\n",
    "    val.append(prepare_datapoints(row))\n",
    "\n",
    "test = []\n",
    "for index, row in test_data.iterrows():\n",
    "    test.append(prepare_datapoints(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ea3a6c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (dic, f) in zip([all_data, train, val, test, flatten_all_tkg_snapshots], ['tkg_all_data_1010.pickle', 'tkg_train_data_1010.pickle', 'tkg_val_data_1010.pickle', 'tkg_test_data_1010.pickle', 'all_tkg_snapshots_1010.pickle']):\n",
    "    ff = open(os.path.join(data_path, f), 'wb')\n",
    "    pickle.dump(dic, ff)\n",
    "    ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef205696",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts = {}\n",
    "for f in ['tkg_all_data_1010.pickle', 'tkg_train_data_1010.pickle', 'tkg_val_data_1010.pickle', 'tkg_test_data_1010.pickle', 'all_tkg_snapshots_1010.pickle']:\n",
    "    in_file = open(str(data_path + f), 'rb')\n",
    "    data_dicts[f] = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e5f5925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5721\n",
      "4633\n",
      "515\n",
      "573\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dicts['tkg_all_data_1010.pickle']))\n",
    "print(len(data_dicts['tkg_train_data_1010.pickle']))\n",
    "print(len(data_dicts['tkg_val_data_1010.pickle']))\n",
    "print(len(data_dicts['tkg_test_data_1010.pickle']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf4f82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(sentence_df)):\n",
    "#     data = sentence_df.iloc[i]\n",
    "#     head_entity = data['lowered_head']\n",
    "#     relation_word, deal = data['relation'].split('_')[0], data['relation'].split('_')[1]\n",
    "#     tail_entity = data['lowered_tail']\n",
    "#     date = data['publishedAt'].split(\" \")\n",
    "#     date = date[0] + 'T' + date[1] + 'Z'\n",
    "#     quad = (head_entity, data['relation'], tail_entity, date)\n",
    "    \n",
    "#     latest_dict = copy.deepcopy(all_tkg_snapshots[-1])\n",
    "    \n",
    "#     try:\n",
    "#         head_data = latest_dict[head_entity]\n",
    "#         tail_data = latest_dict[tail_entity]\n",
    "\n",
    "#         common_entities = return_common_entities(head_data, tail_data)\n",
    "        \n",
    "#         if relation_word == 'success':\n",
    "#             new_head_tuples = []\n",
    "#             new_tail_tuples = []\n",
    "#             to_be_remove_tuples = []\n",
    "\n",
    "#             if deal == 'acq':\n",
    "#                 # success_acq\n",
    "#                 for d in tail_data:\n",
    "#                     if d[1] == 'owner of (P1830)' or d[1] == 'subsidiary (P355)' or d[1] == 'business division (P199)':\n",
    "#                         # the head_entity now acquires certain assets of the tail and new quads are being added\n",
    "#                         new_tuple = (head_entity, d[1], d[2], date)\n",
    "#                         new_head_tuples.append(new_tuple)\n",
    "\n",
    "#                         # the tail entity is being acquired so all tuples now include an end date\n",
    "#                         end_tuple = d + (date,)\n",
    "#                         new_tail_tuples.append(end_tuple)\n",
    "#                         to_be_remove_tuples.append(d)\n",
    "#                     elif d[1] == 'board member (P3320)' or d[1] == 'owned by (P127)':\n",
    "#                         if not d[2] in common_entities:\n",
    "#                             # the tail entity is being acquired so all tuples now include an end date\n",
    "#                             end_tuple = d + (date,)\n",
    "#                             new_tail_tuples.append(end_tuple)\n",
    "#                             to_be_remove_tuples.append(d)\n",
    "                \n",
    "#                 for h in head_data:\n",
    "#                     # the tail entity is being acquired so all the board member and owned by values now own the tail entity\n",
    "#                     if h[1] == 'board member (P3320)' or h[1] == 'owned by (P127)':\n",
    "#                         new_tuple = (tail_entity, h[1], h[2], date)\n",
    "#                         new_tail_tuples.append(new_tuple)\n",
    "\n",
    "#                 # remove outdated tuples\n",
    "#                 for z in to_be_remove_tuples:\n",
    "#                     latest_dict[tail_entity].remove(z)\n",
    "\n",
    "#                 # add new tuples\n",
    "#                 latest_dict[head_entity].append(quad)\n",
    "#                 latest_dict[head_entity] = latest_dict[head_entity] + new_head_tuples\n",
    "#                 latest_dict[tail_entity] = latest_dict[tail_entity] + new_tail_tuples\n",
    "#             elif deal == 'merger':\n",
    "#                 # success_merger\n",
    "#                 latest_dict[head_entity].append(quad)\n",
    "#         else:\n",
    "#             # all other relations\n",
    "#             latest_dict[head_entity].append(quad)\n",
    "#     except:\n",
    "#         if head_entity in latest_dict.keys():\n",
    "#             latest_dict[head_entity].append(quad)\n",
    "#         else:\n",
    "#             latest_dict[head_entity] = [quad]\n",
    "        \n",
    "#         if tail_entity not in latest_dict.keys():\n",
    "#             latest_dict[head_entity] = []\n",
    "    \n",
    "#     all_tkg_snapshots.append(latest_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
